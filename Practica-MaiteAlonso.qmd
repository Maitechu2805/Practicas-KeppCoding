---
format: html
editor: visual
  markdown: 
    wrap: 72
---

Vasmos a cargar el dataset de AirBnB descargado de [aquí](https://public.opendatasoft.com/explore/dataset/airbnb-listings/export/?disjunctive.host_verifications&disjunctive.amenities&disjunctive.features&q=Madrid&dataChart=eyJxdWVyaWVzIjpbeyJjaGFydHMiOlt7InR5cGUiOiJjb2x1bW4iLCJmdW5jIjoiQ09VTlQiLCJ5QXhpcyI6Imhvc3RfbGlzdGluZ3NfY291bnQiLCJzY2llbnRpZmljRGlzcGxheSI6dHJ1ZSwiY29sb3IiOiJyYW5nZS1jdXN0b20ifV0sInhBeGlzIjoiY2l0eSIsIm1heHBvaW50cyI6IiIsInRpbWVzY2FsZSI6IiIsInNvcnQiOiIiLCJzZXJpZXNCcmVha2Rvd24iOiJyb29tX3R5cGUiLCJjb25maWciOnsiZGF0YXNldCI6ImFpcmJuYi1saXN0aW5ncyIsIm9wdGlvbnMiOnsiZGlzanVuY3RpdmUuaG9zdF92ZXJpZmljYXRpb25zIjp0cnVlLCJkaXNqdW5jdGl2ZS5hbWVuaXRpZXMiOnRydWUsImRpc2p1bmN0aXZlLmZlYXR1cmVzIjp0cnVlfX19XSwidGltZXNjYWxlIjoiIiwiZGlzcGxheUxlZ2VuZCI6dHJ1ZSwiYWxpZ25Nb250aCI6dHJ1ZX0%3D&location=16,41.38377,2.15774&basemap=jawg.streets)

![](descargar.png)

```{r}
rm(list = ls())
airbnb<-read.csv('airbnb-listings.csv',sep = ';')
options(repr.plot.height=4,repr.plot.width=6,repr.plot.res = 300)
```

1.  Vamos a quedarnos con las columnas de mayor interés: 'City','Room.Type','Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude' Nos quedarmos solo con las entradas de Madrid para Room.Type=="Entire home/apt" y cuyo barrio (Neighbourhood) no está vacio '' Podemos eliminar las siguientes columnas que ya no son necesarias: "Room.Type",'City' Llama a nuevo dataframe df_madrid.

```{r}
airbnb <- airbnb[, c('City','Room.Type','Neighbourhood','Accommodates','Bathrooms','Bedrooms','Beds','Price','Square.Feet','Guests.Included','Extra.People','Review.Scores.Rating','Latitude', 'Longitude')]
airbnb <- subset(airbnb, airbnb$City == 'Madrid' & airbnb$Room.Type=="Entire home/apt" & airbnb$Neighbourhood != '')
df_madrid <- airbnb[, !names(airbnb) %in% c("Room.Type",'City')]
```

2.  Crea una nueva columna llamada Square.Meters a partir de Square.Feet. Recuerda que un pie cuadrado son 0.092903 metros cuadrados.

```{r}
df_madrid$Square.Meters <- df_madrid$Square.Feet*0.092903
```

3.  ¿Que porcentaje de los apartamentos no muestran los metros cuadrados? Es decir, ¿cuantos tienen NA en Square.Meters?

```{r}
X <- df_madrid[is.na(df_madrid$Square.Meters),]
print(paste("El", 100*round(length(X$Square.Meters)/length(df_madrid$Square.Meters),2), "% de los apartamentos no muestran los metros cuadrados."))
```

4.  De todos los apartamentos que tienen un valor de metros cuadrados diferente de NA ¿Que porcentaje de los apartamentos tienen 0 metros cuadrados?

```{r}
y <- df_madrid[!is.na(df_madrid$Square.Meters),]
z <- y[y$Square.Meters==0, ]
print(paste("El", 100*round(length(z$Square.Meters)/length(y$Square.Meters),2), "% de los apartamentos tienen 0 metros cuadrados."))
```

5.  Reemplazar todos los 0m\^2 por NA

```{r}
df_madrid$Square.Meters <- ifelse(df_madrid$Square.Meters == 0, NA, df_madrid$Square.Meters)

```

Hay muchos NAs, vamos a intentar crear un modelo que nos prediga cuantos son los metros cuadrados en función del resto de variables para tratar de rellenar esos NA. Pero **antes de crear el modelo** vamos a hacer: \* pintar el histograma de los metros cuadrados y ver si tenemos que filtrar algún elemento más. \* crear una variable sintética nueva basada en la similitud entre barrios que usaremos en nuestro modelo.

6.  Pinta el histograma de los metros cuadrados y ver si tenemos que filtrar algún elemento más

```{r}
library(ggplot2)

ggplot(df_madrid, aes(x = Square.Meters)) +
  geom_histogram(bins = 30, fill = "lightblue", color = "black") +
  labs(title = "Histograma", x = "m2", y = "Frecuencia")


```

7.  Asigna el valor NA a la columna Square.Meters de los apartamentos que tengan menos de 20 m\^2

```{r}
df_madrid$Square.Meters <- ifelse(df_madrid$Square.Meters < 20, NA, df_madrid$Square.Meters)

```

8.  Existen varios Barrios que todas sus entradas de Square.Meters son NA, vamos a eliminar del dataset todos los pisos que pertenecen a estos barrios.

```{r}
library(dplyr)
Neighbourhood2delet <- df_madrid %>% group_by(Neighbourhood) %>% summarize(Sum_SquareMeters = sum(Square.Meters, na.rm = TRUE)) %>% filter(Sum_SquareMeters == 0)
#Neighbourhood2delet
df_madrid <- df_madrid[!df_madrid$Neighbourhood %in% Neighbourhood2delet$Neighbourhood,]
#df_madrid %>%
#  filter(Neighbourhood %in% Neighbourhood2delet$Neighbourhood)
```

9.  ¿Tienen todos los barrios los mismos metros cuadrados de media? ¿Con que test lo comprobarías?

```{r}
cat("Para comprobar si la media de metros cuadrados es igual en todos los barrios, tenemos que utilizar un test que compare medias entre varios grupos. tenemos dos alternativas:\n",
    "1.- ANOVA, si dentro de cada grupo hay normalidad y homogeneidad de varianzas.\n",
    "2.- Kruskal-Wallis, si no podemos asumir normalidad dentro de cada grupo.\n",
    "Por lo tanto, primero tenemos que realizar un test de Shapiro-Wilk y un test de Levene a cada barrio.")
```

```{r}
cat("Vamos a comprobar que tenemos entre 5 y 5000 datos por barrio para poder aplicar correctamente los tests de normalidad.\nFiltramos los barrios con suficientes datos.\n")

df_madrid_filtrado <- df_madrid %>%
  group_by(Neighbourhood) %>%
  filter(n() >= 5, n() <= 5000)

# Comprobamos si queda algún barrio fuera del rango
df_madrid_filtrado %>%
  count(Neighbourhood) %>%
  filter(n < 5 | n > 5000)

```
```{r}
cat("Vamos a aplicar un test de normalidad a cada barrio (Shapiro-Wilk)")

# Dividir los datos por barrio
grupos <- df_madrid_filtrado %>%
  group_by(Neighbourhood) %>%
  group_split()

# Aplicar el test a cada grupo
shapiro_por_barrio <- lapply(grupos, function(g) {
  barrio <- unique(g$Neighbourhood)
  n <- nrow(g)
  pval <- tryCatch(shapiro.test(g$Square.Meters)$p.value, error = function(e) NA)
  data.frame(Neighbourhood = barrio, n = n, p_value = pval)
}) %>%
  bind_rows()
shapiro_por_barrio %>%
  filter(p_value < 0.05)
```
```{r}
cat("Cinco barrios no siguen una distribución normal, por lo tanto, utilizamos la alternativa no paramétrica al ANOVA")
```
```{r}
kruskal.test(Square.Meters ~ Neighbourhood, data = df_madrid_filtrado)
```
```{r}
cat("En el test de Kurskal-Wallis\n",
    "H0: las distribuciones de Square.Meters son iguales entre barrios.\n",
    "H1: al menos un barrio tiene una mediana diferente.\n",
    "Como p-value = 0.009755 < 0.05, se rechaza la hipótesis nula, y podemos afirmar que hay diferencias estadísticamente significativas entre barrios.")
```
10. Vamos a agrupar los barrios por metros cuadrados. Podemos usar una matriz de similaridad de Tukey. Muestra como de similares o diferentes son los barrios si nos fijámos únicamente en los metros cuadrados de los pisos. ¿Como se diferencia la media del Barrio A al Barrio B? (Es decir, cual sería el pvalor suponiendo una H0 en la que las medias son iguales)

```{r}
cat("Vamos a ignorar la falta de normalidad y vamos a asumir que ANOVA es adecuado para comparar medias. Luego hacemos comparaciones múltiples con Tukey HSD, que compara todas las parejas de barrios y nos da el p-valor para\n",
    "H0: media(A) = media(B).")

tky<-TukeyHSD(aov( Square.Meters ~ Neighbourhood, data = df_madrid_filtrado))
tky.result<-data.frame(tky$Neighbourhood)
cn <-sort(unique(df_madrid_filtrado$Neighbourhood))
resm <- matrix(NA, length(cn),length(cn))
rownames(resm) <- cn
colnames(resm) <- cn
resm[lower.tri(resm) ] <- round(tky.result$p.adj,4)
resm[upper.tri(resm) ] <- t(resm)[upper.tri(resm)] 
diag(resm) <- 1
# resm
```

11. En el punto anterior has creado una matriz de p-valores que indica como de parecidos son dos barrios. Si su pvalor es bajo significa que los barrios son diferentes, si es alto significa que los barrios se parecen. Esta matriz la podemos usar como matriz de distancia si restamos el pvalor a 1. Es decir si usamos como distancia 1-pvalor. De esta forma barrios con un pvalor alto tendrán una distancia mayor que aquellos con un pvalor bajo. Usando esta última métrica como matriz de distancias dibuja un dendrograma de los diferentes barrios.

```{r}
# crear matriz de distancias: 1 - pvalor
distancia <- 1 - resm

# convertir a objeto
dist_obj <- as.dist(distancia)

# crear cluster jerárquico y dibujar dendograma
barrios.tree <- hclust(dist_obj, method = "complete")
barrios.dend <- as.dendrogram(barrios.tree) 
plot(barrios.dend, main = "Dendrograma de barrios (1 - pvalor)")
```

10. ¿Que punto de corte sería el aconsejable?, ¿cuantos clusters aparecen?

```{r}
# cortar el dendograma a altura 0.1
library(dendextend)
clusters <- cutree(barrios.dend, h=0.1)
plot(color_branches(barrios.dend, h=0.1))

# número total de clusters
cat("Cortando el dendograma a altura 0.1 obtenemos", length(unique(clusters)),
    "clusters")

```

11. Vamos a crear una nueva columna en el dataframe df_madrid con un nuevo identificador marcado por los clusters obtenidos. Esta columna la llamaremos neighb_id

```{r}
# Crear data frame con asignación de clúster
cluster_por_barrio <- data.frame(
  Neighbourhood = names(clusters),
  neighb_id = clusters
)

# Añadir la columna neighb_id a df_madrid
df_madrid_cluster <- df_madrid %>%
  inner_join(cluster_por_barrio[,c('Neighbourhood', 'neighb_id')], by = "Neighbourhood")

# convertir neighb_id en factor
df_madrid_cluster$neighb_id <- factor(df_madrid_cluster$neighb_id)
```

12. Vamos a crear dos grupos, uno test y otro train.

```{r}
set.seed(111)

# Número total de filas
n <- nrow(df_madrid_cluster)

# Índices para el grupo train (70%)
train_indices <- sample(seq_len(n), size = 0.7 * n)

# Crear datasets
df_train <- df_madrid_cluster[train_indices, ]
df_test  <- df_madrid_cluster[-train_indices, ]
```

13. Tratamos de predecir los metros cuadrados en función del resto de columnas del dataframe.

```{r}
# seleccionar solo algunas columnas y eliminar na en conjunto de entrenamiento
df_train_clean <- df_train %>%
  select(Square.Meters, Price, Bathrooms, Bedrooms, Accommodates, neighb_id) %>%
  na.omit()
# ajustar el modelo con las variables seleccionadas
modelo_clean <- lm(Square.Meters ~ Price + Bathrooms + Bedrooms + Accommodates + neighb_id, data = df_train_clean)
summary(modelo_clean)
```

14. Evaluar la calidad de vuestro modelo

```{r}
# Eliminar na del conjunto df_test
df_test_clean <- df_test %>%
  select(Square.Meters, Price, Bathrooms, Bedrooms, Accommodates, neighb_id) %>%
  na.omit()

# PREDICCIONES EN TEST Y RESIDUOS
predicciones <- predict(modelo_clean, newdata = df_test_clean)
real_vs_pred <- data.frame(
  Real = df_test_clean$Square.Meters,
  Predicho = predicciones
)
residuos <- real_vs_pred$Real - real_vs_pred$Predicho

# MÉTRICAS DE EVALUACIÓN
library(Metrics)
mae_val <- mae(real_vs_pred$Real, real_vs_pred$Predicho)
rmse_val <- rmse(real_vs_pred$Real, real_vs_pred$Predicho)
r2_test <- cor(real_vs_pred$Real, real_vs_pred$Predicho)^2
r2_train <- summary(modelo_clean)$r.squared

cat("Evaluación del modelo:\n")
cat("MAE:", round(mae_val, 2), "\n")
cat("RMSE:", round(rmse_val, 2), "\n")
cat("R² test:", round(r2_test, 3), "\n")
cat("R² train:", round(r2_train, 3), "\n")

# GRÁFICOS

# Histograma de residuos
hist(residuos, breaks = 30, main = "Histograma de residuos", xlab = "Residuo", col = "lightblue")

# Real vs Predicho
plot(real_vs_pred$Real, real_vs_pred$Predicho,
     xlab = "Valor Real", ylab = "Valor Predicho",
     main = "Real vs Predicho", pch = 16, col = "darkgreen")
abline(0, 1, col = "red", lwd = 2)

# Residuos vs Predicción
plot(real_vs_pred$Predicho, residuos,
     xlab = "Predicción", ylab = "Residuo",
     main = "Residuos vs Predicción", pch = 16, col = "orange")
abline(h = 0, col = "red", lwd = 2)

# ANÁLISIS DE OUTLIERS

# Residuos estandarizados
residuos_est <- rstandard(modelo_clean)
plot(residuos_est, main = "Residuos estandarizados", ylab = "Residuo estandarizado", pch = 16)
abline(h = c(-2, 2), col = "red", lty = 2)

# Leverage / Cook’s Distance
plot(modelo_clean, which = 4)  # gráfico de Cook's distance

# Identificar observaciones influyentes (Cook > 0.5)
influencia <- cooks.distance(modelo_clean)
outliers_cook <- which(influencia > 0.5)
cat("Observaciones con alta influencia (Cook > 0.5):\n")
print(outliers_cook)
```
```{r}
cat("Vamos a eliminar las observaciones con alta influencia según Cook's Distance y a volver a ajustar y evaluar el modelo.",  
    "La variable neighb_id causa problemas técnicos al eliminar outliers, ya que desaparecen niveles en el grupo de entrenamiento, pero no podemos eliminar esta característica porque podría tener un poder explicativo claro para ciertas zonas (neighb_id3).\n",
    "Como solución, vamos a sustituir neighb_id por una nueva característica: zona_especial para nuestro nuevo modelo sin outliers ")

```
```{r}
# añadir a df_madrid_cluster la columna zona_especial
df_madrid_cluster$zona_especial <- ifelse(df_madrid_cluster$neighb_id == 3, 1, 0)

# Crear datasets
df_train <- df_madrid_cluster[train_indices, ]
df_test  <- df_madrid_cluster[-train_indices, ]

# preparar datos limpios
# Train limpio
df_train_clean <- df_train %>%
  select(Square.Meters, Price, Bathrooms, Bedrooms, Accommodates, zona_especial) %>%
  na.omit()

# Test limpio
df_test_clean <- df_test %>%
  select(Square.Meters, Price, Bathrooms, Bedrooms, Accommodates, zona_especial) %>%
  na.omit()

# ajustar modelo con zona_especial
modelo_zona <- lm(Square.Meters ~ Price + Bathrooms + Bedrooms + Accommodates + zona_especial,
                  data = df_train_clean)

# Eliminar outliers (Cook > 0.5)

influencia <- cooks.distance(modelo_zona)
outliers_cook <- which(influencia > 0.5)

df_train_zona_sin_outliers <- df_train_clean[-outliers_cook, ]

# ajustar modelo definitivo sin outliers

modelo_zona_final <- lm(Square.Meters ~ Price + Bathrooms + Bedrooms + Accommodates + zona_especial,
                        data = df_train_zona_sin_outliers)
summary(modelo_zona_final)

```
```{r}
# comprobamos cuantas observaciones hay en df_train_zona_sin_outliers de cada zona_especial (0 - 1)
table(df_train_zona_sin_outliers$zona_especial)
cat("Vemos que zona_especial aparece como no definida porque no hay ninguna observación con zona especial == 1 tras eliminar los outliers.\n",
    "Ajustamos el modelo sin outliers y eliminando las características neighb_id y zona_especial")

```
```{r}
# Entrenamiento limpio sin zona_especial
df_train_clean_final <- df_train %>%
  select(Square.Meters, Price, Bathrooms, Bedrooms, Accommodates) %>%
  na.omit()

# Test limpio
df_test_clean_final <- df_test %>%
  select(Square.Meters, Price, Bathrooms, Bedrooms, Accommodates) %>%
  na.omit()

# ajustar modelo
modelo_final <- lm(Square.Meters ~ Price + Bathrooms + Bedrooms + Accommodates,
                   data = df_train_clean_final)

# Eliminar outliers (Cook > 0.5)

influencia <- cooks.distance(modelo_final)
outliers_cook <- which(influencia > 0.5)

df_train_final_sin_outliers <- df_train_clean_final[-outliers_cook, ]

# ajustar modelo definitivo sin outliers

modelo_definitivo <- lm(Square.Meters ~ Price + Bathrooms + Bedrooms + Accommodates,
                        data = df_train_final_sin_outliers)

summary(modelo_definitivo)

```
```{r}
# EVALUACIÓN DEL MODELO:
# 1. Predicciones sobre el conjunto test limpio
predicciones_final <- predict(modelo_definitivo, newdata = df_test_clean_final)

# 2. Comparar con valores reales
real_vs_pred_final <- data.frame(
  Real = df_test_clean_final$Square.Meters,
  Predicho = predicciones_final
)

# 3. Calcular residuos
residuos_final <- real_vs_pred_final$Real - real_vs_pred_final$Predicho

# 4. Métricas
library(Metrics)
mae_final <- mae(real_vs_pred_final$Real, real_vs_pred_final$Predicho)
rmse_final <- rmse(real_vs_pred_final$Real, real_vs_pred_final$Predicho)
r2_final_test <- cor(real_vs_pred_final$Real, real_vs_pred_final$Predicho)^2
r2_final_train <- summary(modelo_definitivo)$r.squared

# 5. Mostrar resultados
cat("Evaluación del modelo definitivo:\n")
cat("MAE:", round(mae_final, 2), "m²\n")
cat("RMSE:", round(rmse_final, 2), "m²\n")
cat("R² test:", round(r2_final_test, 3), "\n")
cat("R² train:", round(r2_final_train, 3), "\n")

# 6. Histograma de residuos
hist(residuos_final, breaks = 30, main = "Histograma de residuos", xlab = "Residuo", col = "skyblue")

# 7. Real vs Predicho
plot(real_vs_pred_final$Real, real_vs_pred_final$Predicho,
     xlab = "Valor real", ylab = "Valor predicho",
     main = "Real vs Predicho (modelo definitivo)", pch = 16, col = "darkgreen")
abline(0, 1, col = "red", lwd = 2)

# 8. Residuos vs Predicción
plot(real_vs_pred_final$Predicho, residuos_final,
     xlab = "Predicción", ylab = "Residuo",
     main = "Residuos vs Predicción", pch = 16, col = "orange")
abline(h = 0, col = "red", lwd = 2)
```

```{r}
# GENERAR UNA TABLA COMPARATIVA ENTRE AMBOS MODELOS
comparacion_modelos <- data.frame(
  Modelo = c("Con outliers", "Sin outliers"),
  MAE = c(mae_val, mae_final),
  RMSE = c(rmse_val, rmse_final),
  R2_test = c(r2_test, r2_final_test),
  R2_train = c(r2_train, r2_final_train)
)

# Mostrar tabla
print(comparacion_modelos)
```

```{r}
# CONCLUSIÓN:
cat("Conclusion:\n",
    "El modelo con outliers tiene métricas MAE, RMSE y R2 ligeramente mejores que el modelo sin outliers.\n",
    "En el modelo con outliers R2 train es mayor que R2 test, pero la diferencia es moderada. Podría indicar un ligero sobreajuste.\n",
    "En el modelo sin outliers, esta diferencia es ligeramente menor. Este modelo generaliza mejor.\n",
    "Ambos modelos son válidos, pero el modelo sin outliers es preferible ya que tiene menor sensibilidad a valores extremos. La diferencia de precisión es mínima, y ganamos ligeramente en confianza en la generalización del modelo a nuevos datos.",
    "El histograma de residuos muestra una distribución que, aunque no sigue una distribución perfectamente normal, está razonablemente concentrada y centrada cerca de 0, con una ligera asimetría negativa, con algunos errores negativos extremos. El modelo tiene un error aceptable",
    "Hay una relación positiva clara en el gráfico Real vs Predicho. Observamos dispersión creciente o heterocedasticidad de los errores al aumentar el tamaño de los pisos, lo que nos indica que el modelo es más preciso para viviendas pequeñas y menos para las grandes.",
    "El gráfico Residuos vs Predicción indica que el modelo no mantiene errores constantes (homocedasticidad). Los residuos aumentan su dispersión conforme aumenta la predicción, y tienden a ser negativos en predicciones altas. El modelo subestima las viviendas grandes, se queda corto y predice menos de lo real.")


```

15. Si tuvieramos un anuncio de un apartamento para 6 personas (Accommodates), con 1 baño, con un precio de 80€/noche y 3 habitaciones en el barrio de Sol, con 3 camas y un review de 80. ¿Cuantos metros cuadrados tendría? Si tu modelo necesita algúna variable adicional puedes inventartela dentro del rango de valores del dataset. ¿Como varía sus metros cuadrados con cada habitación adicional?

```{r}
# crear un data frame con las caracteríasticas del nuevo apartamento
nuevo_apartamento <- data.frame(
  Price = 80,
  Bathrooms = 1,
  Bedrooms = 3,
  Accommodates = 6
  )
# predicción con el modelo sin outliers
prediccion_m2 <- predict(modelo_final, newdata = nuevo_apartamento)
cat("Superficie estimada:", round(prediccion_m2, 2), "m²\n")

# Variación de los metros cuadrados en función de la variable bedrooms 
coef_bedrooms <- summary(modelo_final)$coefficients["Bedrooms", "Estimate"]

cat("Cada habitación adicional aumenta un promedio de",
    round(coef_bedrooms, 2), "metros cuadrados.\n")
```

16. Rellenar los Square.Meters con valor NA con el estimado con el modelo anterior.

```{r}
# crear un subconjunto con los elementos que presentan na en la columna Square.Meters
df_na <- df_madrid_cluster %>%
  filter(is.na(Square.Meters)) %>%
  select(Price, Bathrooms, Bedrooms, Accommodates)

# predecir los metros cuadrados con el modelo sin outliers
pred_na <- predict(modelo_final, newdata = df_na)

# rellenar los pisos con na en Square.Meters
df_madrid_cluster$Square.Meters[is.na(df_madrid_cluster$Square.Meters)] <- pred_na

#comprobar que ya no quedan na
sum(is.na(df_madrid_cluster$Square.Meters))
```

```{r}
df_madrid_cluster_na <- df_madrid_cluster %>%
  filter(is.na(Square.Meters)) 
cat("Los elementos en df_Madrid_cluster que todavía tienen na en la columna Square.Meters son pisos que presentan na en alguna de las variables predictoras, por lo que no podemos generar una predicción sobre ellas")
```
